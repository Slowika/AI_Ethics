{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program shows very simple usage of fasttext's wikinews word embeddings by looking at word similarities and word analogies using gensim. \n",
    "\n",
    "To run the program, you will need to:\n",
    "1. Download 'wiki-news-300d-1M.vec.zip' and 'wiki-news-300d-1M-subword.vec.zip' from https://fasttext.cc/docs/en/english-vectors.html  \n",
    "2. Put in a subfolder titled 'wiki-en'\n",
    "3. Install gensim to your virtual environment 'pip install gensim'\n",
    "\n",
    "Then you can run new cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from gensim.models import KeyedVectors\n",
    "#import numpy as np\n",
    "# from sklearn.manifold import TSNE\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need these two files in your folder for this to run properly (this cell will take a long time to run)\n",
    "en_model = KeyedVectors.load_word2vec_format('wiki.en/wiki-news-300d-1M.vec')\n",
    "sw_model = KeyedVectors.load_word2vec_format('wiki.en/wiki-news-300d-1M-subword.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Word with Top Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints the top similar words given one word for the regular and subword embeddings\n",
    "def word_similarity(word):\n",
    "  similar_word= en_model.most_similar(positive=[word])\n",
    "  print(\"Non-subword result:\")\n",
    "  for i in range(5):\n",
    "    print(\"{} ({:.2%})\".format(\n",
    "        similar_word[i][0], similar_word[i][1]))\n",
    "\n",
    "  similar_word= sw_model.most_similar(positive=[word])\n",
    "  print(\"\\nSubword result:\")\n",
    "  for i in range(5):\n",
    "    print(\"{} ({:.2%})\".format(\n",
    "        similar_word[i][0], similar_word[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "boy (86.18%)\n",
      "girls (77.47%)\n",
      "woman (74.41%)\n",
      "lady (72.61%)\n",
      "Girl (71.93%)\n",
      "\n",
      "Subword result:\n",
      "boy (87.73%)\n",
      "girl- (81.40%)\n",
      "girl-girl (78.55%)\n",
      "girly-girl (77.92%)\n",
      "girl-boy (77.81%)\n"
     ]
    }
   ],
   "source": [
    "word_similarity('girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "wheelchairs (80.41%)\n",
      "Wheelchair (70.48%)\n",
      "wheel-chair (68.36%)\n",
      "wheelchair-bound (66.63%)\n",
      "powerchair (65.19%)\n",
      "\n",
      "Subword result:\n",
      "wheelchairs (84.40%)\n",
      "wheelchair-bound (76.75%)\n",
      "wheel-chair (75.34%)\n",
      "wheelchair-accessible (73.51%)\n",
      "wheelchair-using (73.01%)\n"
     ]
    }
   ],
   "source": [
    "word_similarity('wheelchair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "Autism (83.04%)\n",
      "autistic (77.12%)\n",
      "ADHD (69.74%)\n",
      "autism-related (69.41%)\n",
      "non-autistic (66.70%)\n",
      "\n",
      "Subword result:\n",
      "Autism (79.67%)\n",
      "MMR-autism (76.53%)\n",
      "autism-related (74.40%)\n",
      "autistic (74.07%)\n",
      "ADHD (72.68%)\n"
     ]
    }
   ],
   "source": [
    "word_similarity('autism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "non-autistic (82.53%)\n",
      "neurotypicals (79.43%)\n",
      "autists (76.10%)\n",
      "low-functioning (75.66%)\n",
      "aspies (74.55%)\n",
      "\n",
      "Subword result:\n",
      "neurotypicals (83.25%)\n",
      "Neurotypical (75.67%)\n",
      "non-autistic (73.28%)\n",
      "autistic (72.99%)\n",
      "autistics (71.03%)\n"
     ]
    }
   ],
   "source": [
    "word_similarity('neurotypical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "disabilities (79.35%)\n",
      "Disability (78.34%)\n",
      "disabilty (66.93%)\n",
      "disability-related (66.93%)\n",
      "disablity (65.48%)\n",
      "\n",
      "Subword result:\n",
      "disabilty (81.55%)\n",
      "disabilities (80.94%)\n",
      "non-disability (79.30%)\n",
      "disability-related (77.25%)\n",
      "cross-disability (74.04%)\n"
     ]
    }
   ],
   "source": [
    "word_similarity('disability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "handicapped (73.02%)\n",
      "Disabled (70.26%)\n",
      "disable (65.97%)\n",
      "diabled (65.33%)\n",
      "disabling (63.79%)\n",
      "\n",
      "Subword result:\n",
      "non-disabled (80.13%)\n",
      "handicapped (75.37%)\n",
      "nondisabled (74.92%)\n",
      "disabled. (74.38%)\n",
      "diabled (73.78%)\n"
     ]
    }
   ],
   "source": [
    "word_similarity('disabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "Deaf (79.00%)\n",
      "hearing-impaired (71.58%)\n",
      "hard-of-hearing (69.63%)\n",
      "deafness (67.84%)\n",
      "deaf-mute (67.39%)\n",
      "\n",
      "Subword result:\n",
      "deaf-blind (81.17%)\n",
      "deaf-mute (79.24%)\n",
      "non-deaf (78.95%)\n",
      "deafblind (78.08%)\n",
      "hearing-impaired (75.46%)\n"
     ]
    }
   ],
   "source": [
    "word_similarity('deaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "Accessibility (75.92%)\n",
      "accesibility (70.11%)\n",
      "accessability (70.00%)\n",
      "accessibilty (69.57%)\n",
      "accessiblity (69.34%)\n",
      "\n",
      "Subword result:\n",
      "accessibilty (80.31%)\n",
      "accessability (80.23%)\n",
      "accesibility (79.54%)\n",
      "accessiblity (79.10%)\n",
      "inaccessibility (75.02%)\n"
     ]
    }
   ],
   "source": [
    "word_similarity('accessibility')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words that didn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'neurodivergent' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ec37947a718d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'neurodivergent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-b4f1a7e3f603>\u001b[0m in \u001b[0;36mword_similarity\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# prints the top similar words given one word for the regular and subword embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mword_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0msimilar_word\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0men_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Non-subword result:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\ai4g_p\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\ai4g_p\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'neurodivergent' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "word_similarity('neurodivergent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'neuroatypical' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0e72f6a0001f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'neuroatypical'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-b4f1a7e3f603>\u001b[0m in \u001b[0;36mword_similarity\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# prints the top similar words given one word for the regular and subword embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mword_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0msimilar_word\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0men_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Non-subword result:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\ai4g_p\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\ai4g_p\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'neuroatypical' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "word_similarity('neuroatypical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Word Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints the similarity percentages for two words given a comparison word\n",
    "def compare(worda, wordb, com_word):\n",
    "  print(\"Non-subword result:\")\n",
    "  print(\"{} and {}: {:.2%}\".format(worda, com_word, en_model.similarity(worda, com_word)))\n",
    "  print(\"{} and {}: {:.2%}\".format(wordb, com_word, en_model.similarity(wordb, com_word)))\n",
    "\n",
    "  print(\"\\nSubword result:\")\n",
    "  print(\"{} and {}: {:.2%}\".format(worda, com_word, sw_model.similarity(worda, com_word)))\n",
    "  print(\"{} and {}: {:.2%}\".format(wordb, com_word, sw_model.similarity(wordb, com_word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "man and doctor: 53.02%\n",
      "woman and doctor: 58.92%\n",
      "\n",
      "Subword result:\n",
      "man and doctor: 53.79%\n",
      "woman and doctor: 57.38%\n"
     ]
    }
   ],
   "source": [
    "compare('man','woman', 'doctor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "man and nurse: 44.37%\n",
      "woman and nurse: 57.77%\n",
      "\n",
      "Subword result:\n",
      "man and nurse: 46.69%\n",
      "woman and nurse: 57.18%\n"
     ]
    }
   ],
   "source": [
    "compare('man','woman', 'nurse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-subword result:\n",
      "adult and productivity: 29.30%\n",
      "elder and productivity: 27.10%\n",
      "\n",
      "Subword result:\n",
      "adult and productivity: 31.16%\n",
      "elder and productivity: 17.17%\n"
     ]
    }
   ],
   "source": [
    "compare('adult', 'elder', 'productivity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to solve word analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is to B as C is to D\n",
    "def word_analogy(worda, wordb, wordc):\n",
    "  print(\"{} is to {} as {} is to {}\".format(worda, wordb, wordc, \n",
    "                                            en_model.most_similar(negative=[worda], positive=[wordb, wordc])[0][0]) )\n",
    "\n",
    "def sw_word_analogy(worda, wordb, wordc):\n",
    "  print(\"{} is to {} as {} is to {}\".format(worda, wordb, wordc, \n",
    "                                            sw_model.most_similar(negative=[worda], positive=[wordb, wordc])[0][0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man is to king as woman is to queen\n",
      "grass is to green as sky is to blue\n",
      "human is to house as bird is to mansion\n",
      "USA is to Canada as fries is to poutine\n",
      "USA is to France as fries is to frites\n"
     ]
    }
   ],
   "source": [
    "word_analogy('man', 'king', 'woman')\n",
    "word_analogy('grass', 'green', 'sky')\n",
    "word_analogy('human', 'house', 'bird') \n",
    "word_analogy('USA', 'Canada', 'fries')\n",
    "word_analogy('USA', 'France', 'fries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man is to king as woman is to queen\n",
      "grass is to green as sky is to blue\n",
      "human is to house as bird is to birdhouse\n",
      "USA is to Canada as fries is to poutine\n",
      "USA is to France as fries is to frites\n"
     ]
    }
   ],
   "source": [
    "sw_word_analogy('man', 'king', 'woman')\n",
    "sw_word_analogy('grass', 'green', 'sky')\n",
    "sw_word_analogy('human', 'house', 'bird') \n",
    "sw_word_analogy('USA', 'Canada', 'fries')\n",
    "sw_word_analogy('USA', 'France', 'fries')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
